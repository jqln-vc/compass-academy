#

||
|---|
|![Banner](/assets/banner-sprint2-desafio.png)|
||

## SE√á√ïES

- **Compreens√£o Inicial dos Dados** [÷ç]()
  - Diagrama Conceitual [÷ç]()
    - Tratamento de Dados [÷ç]()
    - Data de Loca√ß√£o e Data de Entrega [÷ç]()
    - Hora de Loca√ß√£o e Hora de Entrega [÷ç]()
  - B√¥nus Investigativo [÷ç]()
- **Contextualiza√ß√£o: Sistemas OLTP x OLAP** [÷ç]()
  - Sistemas-Fonte: Normaliza√ß√£o [÷ç]()
  - Data Warehouse: Modelagem Dimensional [÷ç]()
- **Metodologia Adotada: H√≠brido de Inmon e Kimball** [÷ç]() 
- **Processo de Normaliza√ß√£o** [÷ç]()
  - 1NF [÷ç]()
  - 2NF [÷ç]()
  - 3NF [÷ç]()
  - Concession√°ria: Banco Relacional Normalizado [÷ç]()
    - Obtendo a Kilometragem Atual: Exemplo de Implementa√ß√£o com View [÷ç]()
- **Processo de Modelagem Dimensional** [÷ç]()
  - Surrogate Keys: Chaves Substitutas [÷ç]()
  - Tabela-Fato Loca√ß√£o: Tipo Snapshot Acumulativo [÷ç]()
    - Dimens√£o Data: Tipo Role-Playing [÷ç]()
  - Star Schema [÷ç]()
  - Snowflake Schema [÷ç]()
  - Cube Slicing: Exemplo de An√°lise Multidimensional [÷ç]()
- **Considera√ß√µes Finais** [÷ç]()
- **Refer√™ncias** [÷ç]()

## COMPREENS√ÉO INICIAL DOS DADOS

*Voltar para **Se√ß√µes*** [÷ç]()

Antes de iniciar qualquer processamento, √© preciso compreender n√£o somente os dados a serem tratados, mas tamb√©m qual seu contexto de utiliza√ß√£o, a finalidade das transforma√ß√µes a serem feitas, bem como uma proje√ß√£o de necessidades de neg√≥cio futuras.

As etapas de **normaliza√ß√£o** e **modelagem dimensional** foram projetadas considerando o sistema em que esses dados seriam encontrados e quais tipos de a√ß√µes seriam aplicadas em cada contexto.

Primeiramente, os dados foram observados em seu estado bruto.

![Dados Raw](../evidencias/1-concessionaria-original.png)

Por meio de explora√ß√µes iniciais, foi poss√≠vel identificar algumas rela√ß√µes j√° presentes entre valores, relevantes para a etapa de normaliza√ß√£o, e s√≥ ent√£o foi tra√ßado um diagrama conceitual. A seguir, algumas dessas rela√ß√µes n√£o triviais:

**1. Os dados em `kmCarro` s√£o vari√°veis de acordo com o `idLocacao`, logo, independem da entidade `Carro`.**

```sql
    SELECT idLocacao,
	       idCarro,
	       modeloCarro,
	       kmCarro
    FROM tb_locacao
    ORDER BY idCarro ASC, kmCarro DESC;
```

![Km dos Carros](../evidencias/9-kmcarro.png)

> ‚ùó Na se√ß√£o [***Obtendo A Kilometragem Atual: Exemplo Com View***](), ser√° mostrada uma maneira de obter os valores de kilometragem para cada ve√≠culo, de modo a facilitar a an√°lise operacional sem comprometer a **normaliza√ß√£o** do banco relacional.

**2. Em um √∫nico caso, o dado `vlrDiaria` apresentou varia√ß√£o para o mesmo `idCarro`, logo, tamb√©m n√£o poderia ser inferido por essa entidade, e foi associado ao `idLocacao`.**

```sql
    SELECT idCarro, 
           modeloCarro, 
           idLocacao, 
           vlrDiaria
    FROM tb_locacao
    WHERE idCarro IN (
        SELECT idCarro
        FROM tb_locacao
        GROUP BY idCarro
        HAVING COUNT(DISTINCT vlrDiaria) > 1
    )
    ORDER BY idCarro;
```

![Varia√ß√£o Valor Di√°ria](../evidencias/8-variacao-vlr-diaria.png)

A partir dessas observa√ß√µes, foi constru√≠do o diagrama conceitual para fundamentar os processos seguintes. Nesta etapa, somente foi considerada a organiza√ß√£o de entidades e seus atributos, e a cardinalidade dos relacionamentos entre entidades.

### DIAGRAMA CONCEITUAL

*Voltar para **Se√ß√µes*** [÷ç]()

[//]: # (Caso n√£o possua suporte para mermaid, sugiro abrir no site do GitHub para visualizar o diagrama a seguir ou instalar extens√£o compat√≠vel)

```mermaid
erDiagram
    CLIENTE ||--|{ LOCACAO : aluga
    CLIENTE {
        int id
        varchar nome
        varchar cidade
        varchar estado
        varchar pais
    }
    VENDEDOR ||--o{ LOCACAO : vende
    VENDEDOR {
        int id
        varchar nome
        smallint sexo
        varchar estado
    }
    LOCACAO {
        int id
        int cliente_id
        int vendedor_id
        int carro_id
        date data_locacao
        time hora_locacao
        int qtd_diaria
        decimal vlr_diaria
        date data_entrega
        time hora_entrega
        int km_carro
    }
    CARRO ||--o{ LOCACAO : alugado
    CARRO {
        int id
        varchar classi
        varchar marca
        varchar modelo
        int ano
        int combustivel_id
        varchar tipo_combustivel
    }
```

### TRATAMENTO DE DADOS

*Voltar para **Se√ß√µes*** [÷ç]()

Analisando o formato das datas e horas, nota-se uma inconsist√™ncia que prejudica o reconhecimento e manipula√ß√£o dos tipos de dados corretamente. Em SQLite, os formatos de datas e horas devem ser `YYYY-MM-DD` e `HH:MM`, respectivamente.

```sql
    SELECT dataLocacao,
	       horaLocacao,
	       dataEntrega,
	       horaEntrega
    FROM tb_locacao
    ORDER BY horaLocacao;
```

Abaixo, j√° √© poss√≠vel notar um problema gerado pela n√£o adequa√ß√£o dos valores aos tipos: ao ordernarmos as horas de loca√ß√£o de modo ascendente, o valor `8:00` n√£o √© reconhecido, e fica fora de ordem.

![Data e Hora Inconsistentes](../evidencias/11-hora-data.png)

#### DATA DE LOCA√á√ÉO E DATA DE ENTREGA

*Voltar para **Se√ß√µes*** [÷ç]()

Durante a popula√ß√£o das tabelas normalizadas j√° criadas, foi utilizada a tratativa abaixo para cada atributo de data, na qual s√£o selecionados ano, m√™s e dia com a fun√ß√£o `SUBSTR` , separados por `-` por meio do operador de concatena√ß√£o `||`.

- **SUBSTR ( *string*, *in√≠cio*, [*quantidade de caracteres*] )** : a fun√ß√£o subtrai e retorna um trecho de uma string, identificada pelo index do caractere (iniciado em 1).

```sql
    SUBSTR(dataLocacao, 1, 4) || '-' || 
    SUBSTR(dataLocacao, 5, 2) || '-' || 
    SUBSTR(dataLocacao, 7, 2) AS dataLocacao
```

Al√©m disso, os tipos dos atributos divergiam em `DATE` e `DATETIME`; na cria√ß√£o da tabela de loca√ß√£o normalizada, foi mantido o tipo `DATE` para ambas.

#### HORA DE LOCA√á√ÉO E HORA DE ENTREGA

*Voltar para **Se√ß√µes*** [÷ç]()

Para a tratativa dos dados de hora, foi necess√°rio assegurar que a por√ß√£o das horas no formato `HH:MM` sempre conteriam 2 d√≠gitos; por exemplo, o valor `8:00` deve aparecer como `08:00` para ser reconhecido devidamente como tipo `TIME`.

- **INSTR ( *string*, *trecho buscado* )** : a fun√ß√£o localiza e retorna o index do trecho buscado na string.
  - No caso de sele√ß√£o de **hora**, ao subtrair 1 do index retornado para o separador `:` obt√©m-se:

    - `8:00` 1, para casos de hora com 1 d√≠gito  
    - `12:00` 2, para casos de hora com 2 d√≠gitos
  - Para sele√ß√£o de **minutos**, soma-se 1 ao index retornado.
  - O valor retornado por esta fun√ß√£o √© inserido como par√¢metro da fun√ß√£o SUBSTR.
- **PRINTF ( *formato*, *valor1*, *[valor2]* )** : a fun√ß√£o recebe os 2 inteiros referentes √† hora e aos minutos, retornados na etapa anterior, e aplica o formato `%02d:%02d` passado como par√¢metro.
  
  - `%` indica o in√≠cio de um formato
  - `0` valor de preenchimento, caso o valor passado por par√¢metro n√£o contenha o mesmo n√∫mero de d√≠gitos determinado
  - `2d` quantidade de d√≠gitos determinada
  - `:` valor literal que separa horas e minutos

```sql
    PRINTF('%02d:%02d', 
        CAST(SUBSTR(horaLocacao, 1, INSTR(horaLocacao, ':') - 1) AS INTEGER),
        CAST(SUBSTR(horaLocacao, INSTR(horaLocacao, ':') + 1) AS INTEGER)
    	) AS horaLocacao
```

### B√îNUS INVESTIGATIVO üïµüèΩ‚Äç‚ôÄÔ∏è

*Voltar para **Se√ß√µes*** [÷ç]()

Durante a an√°lise do atributo `kmCarro`, foi notada uma inconsist√™ncia nas transa√ß√µes, na qual um dos ids apresenta uma data de loca√ß√£o posterior √† data de entrega. Veja mais abaixo:

```sql
    SELECT idCarro, 
           modeloCarro, 
           kmCarro,
           idLocacao,
           dataLocacao,
           horaLocacao,
           dataEntrega,
           horaEntrega 
    FROM tb_locacao
    ORDER BY idCarro, kmCarro DESC;
```

Ao rodar a query acima, nota-se um problema nas transa√ß√µes de ids 15 e 16.

![Investiga√ß√£o](../evidencias/7-bonus-investigativo.png)

Suspeito? No m√≠nimo. Necess√°rio manter as observa√ß√µes e coletar mais ind√≠cios de atividades fraudulentas. üßêüîé

## CONTEXTUALIZA√á√ÉO: SISTEMAS OLTP X OLAP

*Voltar para **Se√ß√µes*** [÷ç]()

### SISTEMAS-FONTE: NORMALIZA√á√ÉO

*Voltar para **Se√ß√µes*** [÷ç]()

O processo de **normaliza√ß√£o** de dados √© caracter√≠stico de sistemas OLTP, *Online Transaction Processing*, nos quais ocorrem transa√ß√µes em tempo real e demandam a utiliza√ß√£o do banco de dados para processos CRUD: cria√ß√£o, leitura, atualiza√ß√£o e dele√ß√£o. √â um sistema com intuito operacional e est√° atrelado √†s aplica√ß√µes do neg√≥cio.

Os objetivos buscados com a **normaliza√ß√£o** s√£o (CODD, 1971, p. 1):

1. *Liberar a cole√ß√£o de rela√ß√µes de depend√™ncias indesej√°veis de inser√ß√£o, atualiza√ß√£o e dele√ß√£o;*
2. *minimizar a necessidade de reestrutura√ß√£o da cole√ß√£o de rela√ß√µes conforme novos tipos de dados s√£o introduzidos e, com isso, aumentando o tempo de vida das aplica√ß√µes;*
3. *tornar o modelo relacional mais informativo para os usu√°rios;*
4. *tornar a cole√ß√£o de rela√ß√µes neutra em rela√ß√£o √†s estat√≠sticas de queries, visto que estas est√£o sujeitas a mudan√ßas com o passar do tempo.*

Considerando sua aplica√ß√£o, em geral, tomaram-se as decis√µes para as formas normais:

- padroniza√ß√£o de tipos de dados
- elimina√ß√£o de dados duplicados
- restri√ß√µes de unicidade e valores n√£o nulos, com tratamento para casos em que poderiam ocorrer

### DATA WAREHOUSE: MODELAGEM DIMENSIONAL

*Voltar para **Se√ß√µes*** [÷ç]()

O processo de **modelagem dimensional** √© caracter√≠stico de sistemas OLAP, *Online Analytical Processing*, nos quais o foco principal √© a consolida√ß√£o de diversos bancos de dados provenientes de sistemas-fonte diferentes, buscando uma vis√£o hist√≥rica do neg√≥cio para an√°lises mais complexas e suporte √† tomada de decis√µes.

## METODOLOGIA ADOTADA: H√çBRIDO DE KIMBALL E INMON

Abaixo uma hibridiza√ß√£o das metodologias de Inmon e Kimball, a qual serviu de inspira√ß√£o para a arquitetura planejada para o projeto `Concession√°ria` (SERRA, 2024, p. 118):

![Modelo H√≠brido](../../assets/guide-data-modeling-hybrid.png)

A seguir a estrutura da implementa√ß√£o adotada para o projeto, a ser detalhada adiante:

[//]: # (Caso n√£o possua suporte para mermaid, sugiro abrir no site do GitHub para visualizar o diagrama a seguir ou instalar extens√£o compat√≠vel)

```mermaid
flowchart LR
    BD1@{ shape: lin-cyl}
    BD2@{ shape: lin-cyl}
    BD3@{ shape: lin-cyl}
    DW1@{ shape: st-rect, label: "1: STAGING LAYER:\n Tabelas Normalizadas de Fontes Diversas"}
    DW2@{ shape: rect, label: "2: CIF:\n Consolida√ß√£o em Tabelas Normalizadas"}
    DW3@{ shape: rect, label: "3: CORE & ACCESS LAYER:\n Tabelas Fato e Dimens√£o"}
    DW4@{ shape: das, label: "4: SERVING LAYER:\nCubos"}
    DM1@{ shape: cyl, label: "CUBO\nMarketing"}
    DM2@{ shape: cyl, label: "CUBO\nFinanceiro"}
    DM3@{ shape: cyl, label: "CUBO\nManuten√ß√£o"}
    BD1 & BD2 & BD3 == EXTRA√á√ÉO ==> DW1
    DW1 == TRANSFORMA√á√ÉO #1 ==> DW2
    DW2 == TRANSFORMA√á√ÉO #2 ==> DW3
    DW3 --o DW4
    DW4 == DISTRIBUI√á√ÉO ==> DM1 & DM2 & DM3
    T1@{ shape: text, label: "SISTEMAS-FONTE (OLTP)"}
    T2@{ shape: text, label: "DATA WAREHOUSE (OLAP)"}
    T3@{ shape: text, label: "CUBOS (OLAP)"}
    T1 ~~~ T2
    T2 ~~~~~~ T3
    T1 -.-oT2
    T2 -.-oT3
```

1. **Staging Layer**
2. **CIF: Corporate Information Factory**  
   Uma ado√ß√£o do conceito de Inmon de *F√°brica de Informa√ß√£o Corporativa*, aqui os dados provenientes das diversas franquias s√£o integrados, consolidados e preservados.

   > *[...] onde todos os dados s√£o centralizados e armazenados no n√≠vel at√¥mico (o mais granular poss√≠vel) na terceira forma normal. Pode-se considerar como um data warehouse empresarial que √© uma fonte √∫nica da verdade.* (SERRA, 2024, p. 114)

3. **Core & Access Layer**
   Considerando o fato de que um sistema OLAP busca a otimiza√ß√£o para an√°lise trazida com a modelagem dimensional
   
4. **Serving Layer**

> The CIF is off-limits to end users, who access data through the data marts or cubes.
One drawback is that this means the data is permanently duplicated up to three times
for the CIF, the data mart, and the cube. (p. 116)

## PROCESSO DE NORMALIZA√á√ÉO

*Voltar para **Se√ß√µes*** [÷ç]()

> *A inconsist√™ncia nos dados, a dificuldade em codificar o controle na inser√ß√£o de dados, e gerenciamento de erros [...] s√£o riscos reais, assim como empobrecimento em performance e a incapacidade de evolu√ß√£o do modelo. Esses riscos t√™m uma alta probabilidade de ocorrer se n√£o aderimos √†s formas normais.* (FAROULT, p.5)

### 1NF

*Voltar para **Se√ß√µes*** [÷ç]()

- assegurar atomicidade de atributos: separa√ß√£o de atributos multivalorados
- caracteriza√ß√£o de chaves-prim√°rias: localizar (ou criar, quando necess√°rio) o atributo que identifica uma linha como √∫nica.

### 2NF

*Voltar para **Se√ß√µes*** [÷ç]()

> *To remove dependencies on a part of the key, we must create tables (such ascar_model).The keys of those new tables will each be a part of the key for our original table (in ourexample, make, model, version, and style). Then we must move all the attributes thatdepend on those new keys to the new tables, and retain only make, model, version, andstyle in the original table. We may have to repeat this process, since the engine and itscharacteristics will not depend on the style. Once we have completed the removal ofattributes that depend on only a part of the key, our tables are insecond normal form (2NF).* (FAROULT, p. 9)

> There are two issues with the storage ofredundant data. First, redundant data increases the odds of encountering contra-dictory information because of input errors (and it makes correction more time-consuming). Second, redundant data is an obvious storage waste. [...] Besidesthe mere cost of storage, sometimes‚Äîmore importantly‚Äîthere is also the issueof recovery. [...] a database that is twice as big as necessarywill take twice the time to restore than would otherwise be needed. (FAROULT, p. 9)


### 3NF

*Voltar para **Se√ß√µes*** [÷ç]()

> 3NF is reached when we cannotinfer the value of an attribute from any attribute other than those in the unique key. FAROULT, p. 9
>
> duplicate data is costly, both in terms of disk spaceand processing power, but it also introduces a much-increased possibility of databecoming corrupt. Corruption happens when one instance of a data value ismodified, but the same data held in another part of the database fails to be simul-taneously (and identically) modified. (FAROULT, p.10)

### CONCESSION√ÅRIA: BANCO RELACIONAL NORMALIZADO

*Voltar para **Se√ß√µes*** [÷ç]()

A seguir, a execu√ß√£o do script de normaliza√ß√£o:

![Execu√ß√£o Normaliza√ß√£o](../evidencias/1-normalizacao-execucao.gif)

![Banco Normalizado](../evidencias/4-concessionaria_normalizado.png)

#### OBTENDO A KILOMETRAGEM ATUAL: EXEMPLO DE IMPLEMENTA√á√ÉO COM VIEW

*Voltar para **Se√ß√µes*** [÷ç]()

Uma obje√ß√£o dos utilizadores do banco de dados, com a remo√ß√£o da rela√ß√£o de km com o id dos ve√≠culos ap√≥s a normaliza√ß√£o, pode ser a n√£o trivialidade no acesso do valor atual de kilometragem para cada ve√≠culo da base.

Retomando a 1¬™ e 4¬™ motiva√ß√µes de Codd, o banco normalizado busca a otimiza√ß√£o de inser√ß√£o, atualiza√ß√£o e dele√ß√£o (e consultas r√°pidas e pontuais); logo, n√£o √© recomendado prejudicar as depend√™ncias do banco para ater-se a necessidades de buscas espec√≠ficas.

No entanto, esse tipo de problema pode ser facilmente solucionado com a implementa√ß√£o de uma view, tornando os dados normalizados mais intuitivos aos usu√°rios finais:

```sql
    CREATE VIEW kilometragem (
			carro_id,
			classi,
			modelo,
			ano,
			km_atual
	)
    AS
    SELECT car.carro_id,
           car.classi,
           car.modelo,
           car.ano,
           MAX(loc.km_carro) as km_atual
    FROM carro car
    JOIN locacao loc
        ON car.carro_id = loc.carro_id
    GROUP BY car.carro_id, car.modelo
    ORDER BY 1, 3 DESC;
```

A partir da cria√ß√£o da view `kilometragem` , pode-se analisar o portfolio de ve√≠culos, e obter informa√ß√µes como o fato de que "*os ve√≠culos mais rodados n√£o s√£o necessariamente os mais antigos*", como √© poss√≠vel notar no modelo Frontier.

![View Kilometragem](../evidencias/10-view-kilometragem.png)

## PROCESSO DE MODELAGEM DIMENSIONAL

*Voltar para **Se√ß√µes*** [÷ç]()

> *Modelos dimensionais usam um processo chamado **desnormaliza√ß√£o**, no qual voc√™ inclui c√≥pias redundantes dos dados em diversas tabelas. Isso reduz o n√∫mero de tabelas. Quando voc√™ realiza uma busca no banco de dados, n√£o h√° necessidade de fazer joins entre tantas tabelas, tornando a busca muito mais r√°pida. [...] No entanto, significa que as c√≥pias redundantes de dados precisam ser mantidas em sincronia para assegurar a integridade dos dados [...]* (SERRA, 2024, p. 109)

Um **fato** √© caracterizado por:

- num√©rico e mensur√°vel
- medidas e m√©tricas
- n√£o √© l√≥gico (booleano)

A **tabela-fato** cont√©m os fatos, os quais no caso da `Concession√°ria` s√£o caracterizados pelos atributos que definem as transa√ß√µes de loca√ß√µes.

### SURROGATE KEYS: CHAVES SUBSTITUTAS

*Voltar para **Se√ß√µes*** [÷ç]()

Pensando no contexto de data warehouse, os dados extra√≠dos s√£o provenientes de diversos sistemas-fonte, cada um com seu schema e sequ√™ncia de ids de chaves prim√°rias. Durante o processo de consolida√ß√£o desses dados, a boa pr√°tica √© criar **chaves substitutas**, ***surrogate keys***, que servir√£o de chaves prim√°rias e manter√£o a sequ√™ncia e unicidade no data warehouse.

As principais motiva√ß√µes para substitui√ß√£o das chaves naturais origin√°rias s√£o (SERRA, 2024, p.107):

- *podem ser mais longas e complexas do que chaves substitutas e, logo, mais complicadas para lidar;*
- *geralmente cont√™m informa√ß√£o sens√≠vel, o que pode resultar em quest√µes de privacidade;*
- *geralmente geram dificuldades devido a formatos duplicados e despadronizados. [...] Duplica√ß√µes podem ser um problema ao mesclar ou comparar dados entre sistemas diferentes, e a inconsist√™ncia entre formatos pode complicar o processo de integra√ß√£o ainda mais.*

As **chaves naturais**, as chaves prim√°rias trazidas dos sistemas-fonte, podem ser mantidas como refer√™ncia dentro das suas respectivas tabelas dimens√£o.

O projeto atual para a `Concession√°ria` lida com uma √∫nica fonte de dados, no entanto, caso surjam novas franquias, esse seria um problema j√° solucionado. Abaixo, um exemplo de uma poss√≠vel inconsist√™ncia na dimens√£o `Carro` tratada com a utiliza√ß√£o de ***surrogate keys***:

![Surrogate Keys Carro](../evidencias/16-surrogate-key-carro.png)

### TABELA-FATO LOCA√á√ÉO: TIPO SNAPSHOT ACUMULATIVO

*Voltar para **Se√ß√µes*** [÷ç]()

A regra de neg√≥cio identificada pelas transa√ß√µes de loca√ß√£o no projeto `Concession√°ria` indica que cada fato √© demarcado por uma data de in√≠cio, `data_locacao`, e uma data de finaliza√ß√£o, `data_entrega`. Essa caracter√≠stica implica na implementa√ß√£o de uma tabela-fato do tipo **snapshot acumulativo**:

> *Uma linha em uma tabela-fato de snapshot acumulativo sumariza os eventos mensurados que ocorrem em etapas previs√≠veis entre o in√≠cio e o fim de um processo. [...] Existe uma chave-estrangeira de data na tabela-fato para cada etapa cr√≠tica do processo. Uma linha individual [...] √© inicialmente inserida quando a transa√ß√£o √© criada. Conforme o progresso do pipeline ocorre, a linha do fato acumulativo √© revisitada e atualizada.* (KIMBALL, ROSS, p. 44)

In addition to the date
foreign keys associated with each critical process step, accumulating snapshot fact
tables contain foreign keys for other dimensions and optionally contain degenerate dimensions. (KIMBALL, ROSS, p. 44)

> Typically, the dateassociated with a series of measures (a row) in the fact table will not be stored as a datecolumn in the fact table, but as a system-generated number that will reference a row inthedate_dimension table in which the date will bedeclinedunder all possible forms. (p. 265)

![Tabela Fato Loca√ß√£o](../evidencias/14-tabela-fato.png)

#### DIMENS√ÉO DATA: TIPO ROLE-PLAYING

*Voltar para **Se√ß√µes*** [÷ç]()

Uma dimens√£o do tipo **role-playing** √© aquela referenciada mais de uma vez por um fato. Nas tabelas de tipo **snapshot acumulativo** √© comum acontecer com a dimens√£o de tempo, referenciada ao demarcar in√≠cio e fim das etapas temporais de um fato.

No diagrama, a exist√™ncia de uma dimens√£o **role-playing** √© caracterizada por mais de uma rela√ß√£o entre a tabela fato e a dimens√£o.

![Data Dimens√£o Role-Playing](../evidencias/6-data-dimension.png)

### STAR SCHEMA

*Voltar para **Se√ß√µes*** [÷ç]()

- todas as dimens√µes de uma hierarquia representadas em **uma tabela dimensional**
- um √∫nico n√≠vel de dist√¢ncia da **tabela fato**
- menor quantidade de joins necess√°rios
- rela√ß√µes simples entre chave-prim√°ria->chave-estrangeira
- maior armazenamento necess√°rio para dados dimensionais (maior duplica√ß√£o)
- tabela dimens√£o "n√£o-normalizada" (maior duplica√ß√£o)

A partir das tabelas j√° normalizadas, foi executado o script de modelagem dimensional em star schema:

![Star Schema Execu√ß√£o](../evidencias/2-star-schema-execucao.gif)

![Star Schema](../evidencias/5-star-schema.png)

### SNOWFLAKE SCHEMA

*Voltar para **Se√ß√µes*** [÷ç]()

- cada dimens√£o de uma hierarquia representadas em **uma tabela dimensional**
- um ou mais n√≠veis de dist√¢ncia da **tabela fato** ao longo de cada hierarquia
- menor quantidade de joins necess√°rios
- rela√ß√µes complexas entre chave-prim√°ria->chave-estrangeira
- menor armazenamento necess√°rio para dados dimensionais (menor duplica√ß√£o)
- tabela dimens√£o "normalizada" (menor duplica√ß√£o)

![Snowflake Schema Execu√ß√£o](../evidencias/3-snowflake-schema-execucao.gif)

![Snowflake Schema](../evidencias/12-snowflake-schema.png)

### CUBE SLICING: EXEMPLO DE AN√ÅLISE MULTIDIMENSIONAL

*Voltar para **Se√ß√µes*** [÷ç]()

Com a query abaixo, √© demonstrado visualmente o conceito de an√°lise multidimensional por cubos, a qual ocorre na etapa de distribui√ß√£o e consumo dos dados em um sistema OLAP.

> *Um banco de dados OLAP √© tipicamente composto de um ou mais cubos. Em um cubo OLAP, os dados s√£o pr√©-agregados [...] isto √©, j√° foram sumarizados e agrupados por certas dimens√µes [...] Criar um cubo OLAP geralmente involve a utiliza√ß√£o de um modelo multidimensional, o qual utiliza-se de um schema em star ou snowflake para representar os dados.* (SERRA, 2024, p. 92)

```sql
    SELECT loc.carro_key,
	   car.modelo,
	   dt.dia_semana,
	   SUM(loc.qtd_diaria) AS dias_locado,
	   SUM(loc.valor_total) AS lucro_total
    FROM locacao_fact loc
    JOIN carro_dim car
        ON loc.carro_key = car.carro_key 
    JOIN data_dim dt 
        ON loc.data_locacao_key = dt.data_key
    GROUP BY loc.carro_key, dt.dia_semana
    ORDER BY 1 ASC;
```

![An√°lise Cubo](../evidencias/15-analise-cubo.png)

Na metodologia adotada para o projeto `Concession√°ria`, em vista do escopo estreito dos dados tratados, optou-se por n√£o utilizar uma camada de ***data marts***, utilizando a distribui√ß√£o dos dados diretamente por meio de cubos.

Os benef√≠cios advindos da ado√ß√£o de cubos √© mais do que suficiente para o projeto (SERRA, 2024, p. 118):

- proporciona uma camada sem√¢ntica;
- lida com diversos usu√°rios concorrentes;
- obt√©m melhor performance com dados agregados;
- evita a necessidade de lidar com joins e relacionamentos;
- pode conter hierarquias e KPIs;
- integra seguran√ßa ao n√≠vel da tupla/linha, a qual aumenta a privacidade de dados ao restringir acesso de usu√°rio a linhas;espec√≠ficas;
- entre outros.

> *A view tamb√©m pode ser utilizada em cubos. [...] Usar views simplifica o gerenciamento de varia√ß√µes r√°pidas e proporciona controle total de quaisquer joins enviados √† fonte da qual o cubo consome os dados.* (SERRA, 2024, p. 119)

## CONSIDERA√á√ïES FINAIS

*Voltar para **Se√ß√µes*** [÷ç]()

Para o projeto de normaliza√ß√£o e modelagem dimensional da `Concession√°ria` foi levado em conta uma utiliza√ß√£o a m√©dio prazo, com a poss√≠vel integra√ß√£o de outras franquias no projeto, e a utiliza√ß√£o de um data warehouse para a integra√ß√£o e consolida√ß√£o dos dados para an√°lise otimizada do neg√≥cio em sua totalidade.

A normaliza√ß√£o seria, inicialmente, aplicada diretamente nos sistemas OLTP de cada franquia. Sem preju√≠zo de uma nova etapa de normaliza√ß√£o no processo de extra√ß√£o e ingest√£o desses sistemas-fontes no data warehouse, a qual serviria como ***single source of truth*** e um backup potencial para os sistemas-fonte OLTP.

A metodologia adotada foi uma hibridiza√ß√£o dos modelos de Inmon e Kimball, adaptada √†s necessidades atuais do projeto. No entanto, conforme este torna-se mais complexo, existe a possibilidade de agregar novas camadas sem preju√≠zo √† arquitetura atual.

---

## REFER√äNCIAS

*Voltar para **Se√ß√µes*** [÷ç]()

*Publica√ß√µes indicadas na se√ß√£o [Bibliografia](https://github.com/jqln-vc/compass-academy/blob/main/sprint2/README.md#bibliografia), localizada no diret√≥rio `sprint2`.*
